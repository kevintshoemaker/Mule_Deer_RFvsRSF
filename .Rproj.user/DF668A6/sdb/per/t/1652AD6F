{
    "collab_server" : "",
    "contents" : "####################\n## Function for visualizing univariate relations\n####################\n\nVisualizeRelation <- function(data=deer[[\"summer\"]],model=GLMMs[[\"summer\"]],predvar=\"dist_to_water\",type=\"RF\"){\n  len <- 100\n  \n  isfac <- is.factor(data[[predvar]])\n  \n  dataclasses <- sapply(data,class)\n  \n  if(!isfac){\n    if(type==\"GLMM\"){\n      standvar <- sprintf(\"stand_%s\",predvar)\n    }else{\n      standvar <- predvar\n    }\n    dim <- data[,standvar]\n    range <- seq(min(dim),max(dim),length=len)\n    \n    realmean <- mean(data[,predvar])\n    realsd <- sd(data[,predvar])\n    \n    newdata <- data.frame(temp=range)\n    # head(newdata,50)\n    names(newdata) <- c(standvar)\n    if(type==\"GLMM\"){ \n      allvars <- names(model@frame)\n    }else{\n      allvars <- pred.names\n    }\n    othervars <- allvars[!allvars%in%c(standvar,\"used\")]\n  }else{\n    faclevs <- levels(data[[predvar]])\n    newdata <- data.frame(temp=factor(faclevs,levels=faclevs))\n    names(newdata) <- c(predvar)\n    if(type==\"GLMM\"){ \n      allvars <- names(model@frame)\n    }else{\n      allvars <- pred.names\n    }\n    othervars <- allvars[!allvars%in%c(predvar,\"used\")]\n  }\n  \n  var = othervars[2]\n  for(var in othervars){\n    thisvar <- data[,var]\n    if(is.factor(thisvar)){\n      tab <- table(thisvar)\n      vals <- names(tab)\n      levs <- levels(thisvar)\n      mostcom <- vals[which.max(tab)]\n      newvec <- factor(rep(mostcom,times=nrow(newdata)),levels=levs)\n      newdata[,var] <- newvec\n    }else{\n      newdata[,var] <- mean(thisvar)\n    }\n  }\n  \n  if(type==\"GLMM\"){\n    pred <- plogis(predict(model,newdata))\n  }else{\n    i=pred.names[3]\n    for(i in pred.names){\n      if(dataclasses[i]==\"integer\") newdata[,i] <- as.integer(round(newdata[,i]))\n    }\n    pred <- numeric(nrow(newdata))\n    i=1\n    for(i in 1:nrow(newdata)){\n      pred[i]<-as.numeric(predict(model,newdata[i,],OOB=TRUE,type=\"prob\")[[1]][,2])\n    } \n  }\n  \n  if(!isfac){\n    plot(range,pred,xlab=predictorNames[pred.names==predvar],ylab=\"Use probability\",type=\"l\",lwd=2,xaxt=\"n\")\n    ats <- seq(min(range),max(range),length=6)\n    if(type==\"GLMM\"){\n      axis(1,ats,labels = round(realmean+ats*realsd))\n    }else{\n      axis(1,ats,labels = round(ats))\n    }\n    rug(jitter(data[seq(1,nrow(data),50),standvar]), ticksize = 0.03, side = 1, lwd = 0.5, col = par(\"fg\"))\n  }else{\n    par(mai=c(1.5,1,1,.2))\n    plot(pred~newdata[,1],xlab=\"\",main=predictorNames[pred.names==predvar],ylab=\"Use probability\",lwd=2,las=2)\n  }\n}\n\n\n####################\n## Function for visualizing interactions\n####################\n\n\nVisualizeInteraction <- function(data=deer[[\"summer\"]],model=GLMMs[[\"summer\"]],var1=\"dist_to_water\",var2=\"elevation\",type=\"GLMM\"){\n  len <- 50\n  \n  dataclasses <- sapply(data,class)\n  \n  if(type==\"GLMM\"){\n    standvar1 <- sprintf(\"stand_%s\",var1)\n    standvar2 <- sprintf(\"stand_%s\",var2)\n    realmean1 <- mean(data[,var1])\n    realsd1 <- sd(data[,var1])\n    realmean2 <- mean(data[,var2])\n    realsd2 <- sd(data[,var2])\n  }else{\n    standvar1 <- var1\n    standvar2 <- var2\n  }\n  \n  firstdim <- data[,standvar1]\n  seconddim <- data[,standvar2]\n  range1 <- seq(min(firstdim),max(firstdim),length=len)\n  range2 <- seq(min(seconddim),max(seconddim),length=len)\n  newdata <- expand.grid(range1,range2)\n  # head(newdata,50)\n  names(newdata) <- c(standvar1,standvar2)\n  \n  if(type==\"GLMM\"){ \n    allvars <- names(model@frame)\n  }else{\n    allvars <- pred.names\n  }\n  othervars <- allvars[!allvars%in%c(standvar1,standvar2,\"used\")]\n  \n  var = othervars[2]\n  for(var in othervars){\n    thisvar <- data[,var]\n    if(is.factor(thisvar)){\n      tab <- table(thisvar)\n      vals <- names(tab)\n      levs <- levels(thisvar)\n      mostcom <- vals[which.max(tab)]\n      newvec <- factor(rep(mostcom,times=nrow(newdata)),levels=levs)\n      newdata[,var] <- newvec\n    }else{\n      newdata[,var] <- mean(thisvar)\n    }\n  }\n  \n  if(type==\"GLMM\"){\n    pred <- plogis(predict(model,newdata))\n  }else{\n    i=pred.names[3]\n    for(i in pred.names){\n      if(dataclasses[i]==\"integer\") newdata[,i] <- as.integer(round(newdata[,i]))\n    }\n    pred <- numeric(nrow(newdata))\n    i=1\n    for(i in 1:nrow(newdata)){\n      pred[i]<-as.numeric(predict(model,newdata[i,],OOB=TRUE,type=\"prob\")[[1]][,2])\n    } \n  }\n  \n  predmat <-  matrix(pred,nrow=len,ncol=len)\n  \n  par(mai=c(0,0,0,0))\n  \n  if(type==\"GLMM\"){\n    persp(realmean1+realsd1*range1,realmean2+realsd2*range2,predmat,xlab=var1,ylab=var2,theta = 55, phi = 40, r = sqrt(10), d = 3, \n          ticktype = \"detailed\", mgp = c(4, 1, 0))\n  }else{\n    persp(range1,range2,predmat,xlab=var1,ylab=var2,theta = 55, phi = 40, r = sqrt(10), d = 3, \n          ticktype = \"detailed\", mgp = c(4, 1, 0))\n  }\n  \n}\n\n\n#####################\n## CROSS VALIDATION\n#####################\n\nn.folds=3\n\ntype= \"GLMM\" #\"RF\"\nseason=\"summer\"\nfullmodel=GLMMs[[season]] #RFs[[season]]\n\nCrossValidateByDeer <- function(n.folds,season=\"summer\",type=\"GLMM\",plot=F){\n  uniquedeer <- as.character(unique(deer[[season]]$altid))  # list of all unique animals\n  ndeer <- length(uniquedeer)  # total number of inds\n  folds_df <- data.frame( \n    deer = uniquedeer,\n    fold = rep_len(1:n.folds,ndeer)\n  )\n  foldVector <- folds_df$fold[match(as.character(deer[[season]]$altid),folds_df$deer)]\n  \n  predictCols <- which(names(deer[[season]])%in%pred.names)\n  \n  if(type==\"RF\"){\n    fullmodel<-RFs[[season]]\n  }else{\n    fullmodel <- GLMMs[[season]]\n  }\n  \n  CVresults <- list()\n  CVresults$CVpred <- numeric(nrow(deer[[season]]))\n  CVresults$realpred <- numeric(nrow(deer[[season]])) \n  CVresults$observed <- numeric(nrow(deer[[season]]))\n  \n  if(type==\"RF\"){\n    response=\"used_fac\"    #\"resp_factor\"\n  }else{\n    response=\"used\"    #\"resp_factor\"\n  }\n  \n  counter = 1\n  \n  i=n.folds\n  for(i in 1:n.folds){\n    if(type==\"RF\"){\n      model <- cforest(formula1, data = deer[[season]][which(foldVector!=i),], controls=cforestControl) \n      predict_CV  <- predict(model,newdata=deer[[season]][which(foldVector==i),],type=\"prob\") \n      predict_real  <-  predict(fullmodel,newdata=deer[[season]][which(foldVector==i),],type=\"prob\")\n      REAL <- deer[[season]]$used[which(foldVector==i)]\n      j=1\n      for(j in 1:length(which(foldVector==i))){\n        CVresults$CVpred[counter] <- as.numeric(predict_CV[[j]][,2])\n        CVresults$observed[counter] <-  as.numeric(REAL[j])      \n        CVresults$realpred[counter] <- as.numeric(predict_real[[j]][,2])   \n        counter = counter + 1  \n      }\n    }else{\n      \n      model <- glmer(attributes(GLMMs[[season]]@frame)$formula, \n                       family=\"binomial\", data=deer[[season]][which(foldVector!=i),],na.action=\"na.fail\") \n      \n      CVresults$CVpred[which(foldVector==i)]  <- plogis(predict(model,newdata=deer[[season]][which(foldVector==i),],allow.new.levels = TRUE)) \n      CVresults$realpred[which(foldVector==i)] <-  predict(fullmodel,newdata=deer[[season]][which(foldVector==i),],allow.new.levels = TRUE)\n      CVresults$observed[which(foldVector==i)] <- deer[[season]]$used[which(foldVector==i)]      \n    }\n    cat(sprintf(\"fold %s out of %s\\n\",i,n.folds))\n  }\n  \n  CVresults$CV_RMSE = sqrt(mean((CVresults$observed-CVresults$CVpred)^2))       # root mean squared error for holdout samples in 10-fold cross-validation ...\n  CVresults$real_RMSE = sqrt(mean((CVresults$observed-CVresults$realpred)^2))   # root mean squared error for residuals from final model\n  \n  # realprediction <- predict(rf_model1,newdata=df,type=\"prob\")\n  \n  if(plot){\n    graphics.off()\n    par(mfrow=c(2,1))\n    par(ask=T)\n    pred <- prediction(CVresults$CVpred,CVresults$observed)     # for holdout samples in cross-validation\n    perf <- performance(pred,\"tpr\",\"fpr\")\n    auc <- performance(pred,\"auc\")\n    plot(perf, main=sprintf(\"%s Cross Validation\",type))\n    \n    text(.9,.1,paste(\"AUC = \",round(auc@y.values[[1]],2),sep=\"\"))\n    \n    pred <- prediction(CVresults$realpred,CVresults$observed)     # for final model\n    perf <- performance(pred,\"tpr\",\"fpr\")\n    auc <- performance(pred,\"auc\")\n    plot(perf, main=sprintf(\"%s Full Model\",type))\n    text(.9,.1,paste(\"AUC = \",round(auc@y.values[[1]],2),sep=\"\"))\n  }else{\n    pred <- prediction(CVresults$CVpred,CVresults$observed)     # for holdout samples in cross-validation\n    perf <- performance(pred,\"tpr\",\"fpr\")\n    CVresults$auc_CV <- performance(pred,\"auc\")\n    pred <- prediction(CVresults$realpred,CVresults$observed)     # for final model\n    perf <- performance(pred,\"tpr\",\"fpr\")\n    CVresults$auc_full <- performance(pred,\"auc\")\n  }   \n  \n  # COHEN KAPPA statistics\n  \n  thresholds <- seq(0.01,0.99,length=101)   # \"artificial\" extinction thresholds across which to examine performance\n  kappa <- numeric(length(thresholds))\n  for(i in 1:length(thresholds)){\n    trueLabels <- CVresults$observed\n    predLabels <- ifelse(CVresults$CVpred>=thresholds[i],1,0)\n    tot <- length(CVresults$observed)\n    tp <- length(which((trueLabels==1)&(predLabels==1)))  \n    tn <- length(which((trueLabels==0)&(predLabels==0)))\n    fp <- length(which((trueLabels==0)&(predLabels==1)))\n    fn <- length(which((trueLabels==1)&(predLabels==0)))\n    pr_agree <- (tp+tn)/tot    # overall agreement, or accuracy\n    pr_agree_rand <- ((tp+fn)/tot)*((tp+fp)/tot)+((fn+tn)/tot)*((fp+tn)/tot)\n    kappa[i] <- (pr_agree-pr_agree_rand)/(1-pr_agree_rand)\n  }\n  #plot(thresholds,kappa,type=\"l\",xlab=\"Threshold\", ylab=\"Cohen's Kappa\", main=\"Holdout sample performance\")\n  \n  # find threshold value associated with highest Kappa for C-V data\n  \n  CVresults$cutoff_CV <- thresholds[which.max(kappa)]   # max kappa cutoff\n  \n  kappa <- numeric(length(thresholds)) \n  for(i in 1:length(thresholds)){\n    trueLabels <- CVresults$observed\n    predLabels <- ifelse(CVresults$realpred>=thresholds[i],1,0)    \n    tot <- length(CVresults$observed)\n    tp <- length(which((trueLabels==1)&(predLabels==1)))  \n    tn <- length(which((trueLabels==0)&(predLabels==0)))\n    fp <- length(which((trueLabels==0)&(predLabels==1)))\n    fn <- length(which((trueLabels==1)&(predLabels==0)))\n    pr_agree <- (tp+tn)/tot    # overall agreement, or accuracy\n    pr_agree_rand <- ((tp+fn)/tot)*((tp+fp)/tot)+((fn+tn)/tot)*((fp+tn)/tot)\n    kappa[i] <- (pr_agree-pr_agree_rand)/(1-pr_agree_rand)\n  }\n  #plot(thresholds,kappa,type=\"l\",xlab=\"Threshold\", ylab=\"Cohen's Kappa\", main=\"Performance: full model\")\n  \n  CVresults$cutoff_full <- thresholds[which.max(kappa)]   # max kappa cutoff\n  \n  ### display confusion matrix and kappa for a single threshold\n  trueLabels <- CVresults$observed\n  predLabels <- ifelse(CVresults$CVpred>=CVresults$cutoff_CV,1,0)    \n  tot <- length(CVresults$observed)\n  tp <- length(which((trueLabels==1)&(predLabels==1)))  \n  tn <- length(which((trueLabels==0)&(predLabels==0)))\n  fp <- length(which((trueLabels==0)&(predLabels==1)))\n  fn <- length(which((trueLabels==1)&(predLabels==0)))\n  pr_agree <- (tp+tn)/tot    # overall agreement, or accuracy\n  pr_agree_rand <- ((tp+fn)/tot)*((tp+fp)/tot)+((fn+tn)/tot)*((fp+tn)/tot)\n  CVresults$bestkappa_CV <- (pr_agree-pr_agree_rand)/(1-pr_agree_rand)\n  \n  CVresults$confusionmat <- matrix(c(tn,fn,fp,tp),nrow=2,ncol=2)\n  rownames(CVresults$confusionmat) <- c(\"Actual not used\",\"Actual used\")\n  colnames(CVresults$confusionmat) <- c(\"Predicted not used\",\"Predicted used\")\n  \n  CVresults$sensitivity <- tp/(tp+fn)\n  CVresults$specificity <- tn/(tn+fp)\n  CVresults$toterror <- (fn+fp)/tot\n  \n  CVresults$CVpred[which(CVresults$CVpred==1)] <- 0.999999\n  CVresults$CVpred[which(CVresults$CVpred==0)] <- 0.000001\n  CVresults$realpred[which(CVresults$realpred==1)] <- 0.999999\n  CVresults$realpred[which(CVresults$realpred==0)] <- 0.000001\n  \n  realdata = CVresults$observed\n  fit_deviance_CV <- mean(-2*(dbinom(CVresults$observed,1,CVresults$CVpred,log=T)-dbinom(realdata,1,realdata,log=T)))\n  fit_deviance_real <- mean(-2*(dbinom(CVresults$observed,1,CVresults$realpred,log=T)-dbinom(realdata,1,realdata,log=T)))\n  null_deviance <- mean(-2*(dbinom(CVresults$observed,1,mean(CVresults$observed),log=T)-dbinom(realdata,1,realdata,log=T)))\n  CVresults$deviance_explained_CV <- (null_deviance-fit_deviance_CV)/null_deviance   # based on holdout samples\n  CVresults$deviance_explained_real <- (null_deviance-fit_deviance_real)/null_deviance   # based on full model...\n  \n  return(CVresults)\n}\n\n\n\nPlotPerformance <- function(CVresults){\n    graphics.off()\n    par(mfrow=c(2,1))\n    #par(ask=T)\n    pred <- prediction(CVresults$CVpred,CVresults$observed)     # for holdout samples in cross-validation\n    perf <- performance(pred,\"tpr\",\"fpr\")\n    auc <- performance(pred,\"auc\")\n    plot(perf, main=sprintf(\"%s Cross Validation\",type))\n    \n    text(.9,.1,paste(\"AUC = \",round(auc@y.values[[1]],2),sep=\"\"))\n    \n    pred <- prediction(CVresults$realpred,CVresults$observed)     # for final model\n    perf <- performance(pred,\"tpr\",\"fpr\")\n    auc <- performance(pred,\"auc\")\n    plot(perf, main=sprintf(\"%s Full Model\",type))\n    text(.9,.1,paste(\"AUC = \",round(auc@y.values[[1]],2),sep=\"\"))\n}\n\n\n\n\n\n\n\n",
    "created" : 1507310220901.000,
    "dirty" : true,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1892498856",
    "id" : "1652AD6F",
    "lastKnownWriteTime" : 1512159731,
    "last_content_update" : 1512160588962,
    "path" : "E:/GIT/Mule_Deer_RFvsRSF/METHODS_PAPER_ALLFUNCTIONS.R",
    "project_path" : "METHODS_PAPER_ALLFUNCTIONS.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}